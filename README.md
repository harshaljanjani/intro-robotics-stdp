## multimodal-stdp-experiments

This repository contains my first set of experiments using Isaac Sim, where I’m learning about AI and robotics through multimodal STDP-based learning in simulation, and exploring embodied cognition. The work is exploratory and compute-light, focused on understanding biologically inspired learning rules and embodiment rather than building a finished system.

To my knowledge, there are multiple ways this problem is being approached as of October 2025 (these are just a few of the many approaches; I haven’t even mentioned bio-inspired ones, though I’m clearly inspired by many of them as well):

1. The **Fei-Fei Li** / **World Labs** conjecture of spatial intelligence and the Yann LeCun conjecture of world models can largely be grouped together.
2. The **François Chollet** / **Ndea** front: program synthesis, ARC-AGI, continual learning, and meta-learning.
3. The **Figure Robotics** / **Sergey Levine** front: solving general robotics. While the focus here isn’t innovation in AI, something may emerge for AI through systems like Helix.

This work is largely driven by a wave of inspiration from these three directions.
